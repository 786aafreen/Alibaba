{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOiMZdgBuGuJxE2Bc9Opmrd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"DjZuZxNahIhF"},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import datasets, layers, models, losses, Model"]},{"cell_type":"code","source":["'''\n","Then, the data is loaded as in the LeNet implementation. One important notice is that the original ResNet model receives images with the size 224 x 224 x 3 however, \n","MNIST images are 28 x 28. The images are padded with zeros and the third axis is expanded and repeated 3 times to make image sizes 32 x 32 x 3.\n"," When loading the model from Keras, it is possible to indicate the input shape, which will be 32 x 32 x 3 in our case instead of 224 x 224 x 3.\n","'''\n","(x_train,y_train),(x_test,y_test) = datasets.mnist.load_data()\n","x_train = tf.pad(x_train, [[0, 0], [2,2], [2,2]])/255\n","x_test = tf.pad(x_test, [[0, 0], [2,2], [2,2]])/255\n","x_train = tf.expand_dims(x_train, axis=3, name=None)\n","x_test = tf.expand_dims(x_test, axis=3, name=None)\n","x_train = tf.repeat(x_train, 3, axis=3)\n","x_test = tf.repeat(x_test, 3, axis=3)\n","x_val = x_train[-2000:,:,:,:]\n","y_val = y_train[-2000:]\n","x_train = x_train[:-2000,:,:,:]\n","y_train = y_train[:-2000]"],"metadata":{"id":"BiKFyaEThR13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["'''\n","The ResNet model consists of lots and lots of convolutional layers each having 3x3 masks (except the first layer with has 7x7 masks). \n","There are a few variations of the model but ResNet-152 was the model that won ILSVRC in 2015 \n","'''\n","base_model = tf.keras.applications.ResNet152(weights = 'imagenet', include_top = False, input_shape = (32,32,3))\n","for layer in base_model.layers:\n","  layer.trainable = False"],"metadata":{"id":"5VDC0BnAhakZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_model.summary()"],"metadata":{"id":"83fWbgxShdJU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#The top is added as follows:\n","x = layers.Flatten()(base_model.output)\n","x = layers.Dense(1000, activation='relu')(x)\n","predictions = layers.Dense(10, activation = 'softmax')(x)"],"metadata":{"id":"Vrxvflubhja3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["head_model = Model(inputs = base_model.input, outputs = predictions)\n","head_model.compile(optimizer='adam', loss=losses.sparse_categorical_crossentropy, metrics=['accuracy'])"],"metadata":{"id":"adU7FQuqhmFC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["head_model.summary()"],"metadata":{"id":"ktzFALofhofZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = head_model.fit(x_train, y_train, batch_size=64, epochs=40, validation_data=(x_val, y_val))"],"metadata":{"id":"12OoYACDh5q_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fig, axs = plt.subplots(2, 1, figsize=(15,15))\n","axs[0].plot(history.history['loss'])\n","axs[0].plot(history.history['val_loss'])\n","axs[0].title.set_text('Training Loss vs Validation Loss')\n","axs[0].set_xlabel('Epochs')\n","axs[0].set_ylabel('Loss')\n","axs[0].legend(['Train','Val'])\n","axs[1].plot(history.history['accuracy'])\n","axs[1].plot(history.history['val_accuracy'])\n","axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n","axs[1].set_xlabel('Epochs')\n","axs[1].set_ylabel('Accuracy')\n","axs[1].legend(['Train', 'Val'])"],"metadata":{"id":"IJ79CyPAhsIB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["head_model.evaluate(x_test, y_test)"],"metadata":{"id":"mxrtgxtSh__m"},"execution_count":null,"outputs":[]}]}